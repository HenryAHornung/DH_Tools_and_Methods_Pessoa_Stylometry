{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42439e86-6b1c-430c-8416-124a02b70903",
   "metadata": {},
   "source": [
    "# Scraping \"A Little Larger than the Entire Universe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed95c3-ea2f-4971-9ab6-f297ca1d725b",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the code that we wrote to scrape the poems contained in the book, \"A Little Larger than the Entire Universe\". This is a collection of poems written by Pessoa under his own name (77 poems), and his three most prolific heteronyms: Alberto Caeiro (52 poems), Ricardo Reis (56 poems) and Alvaro de Campos (41 poems). Most of the poems were originally written in Portuguese, and translated into English by Richard Zenith, the seminal scholar of Pessoa's life."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc00c2c-0ca9-4016-a05f-381b335aeb4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Importing Modules\n",
    "\n",
    "The following modules were used for the corpus collection and analysis. Please consult the comments within the code to see what each module was used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4e7db6-8ca0-44be-863a-8386be8a1a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Collecting_Data/lib/python3.12/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "[nltk_data] Downloading package punkt_tab to /Users/henry/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/henry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/henry/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing modules\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download the NLTK punkt_tab model that will be used for the sentence tokenization\n",
    "nltk.download('punkt_tab')\n",
    "# Ensure you have the NLTK stopwords set downloaded\n",
    "nltk.download('stopwords')\n",
    "# Loading NLTK stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Download the VADER lexicon which will be used for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "# Initialize VADER Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec42ae7-afa4-41f3-8309-4ec4e1295697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Scraping and Corpus Collection Functions\n",
    "Several functions were created which were applied to page ranges from the PDF which corresponded to the respective heteronyms' poems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6c641-2467-45e0-99d0-214e8c7a0e8d",
   "metadata": {},
   "source": [
    "### 2.1. Importing the poems\n",
    "The function \"ImportPDF\" imports specifed pages from the PDF, where each page is a list entry. the variable \"heteronym\" will define the name of the list, in which the pages are stored. \"heteronym_pages\" denotes which pages of the book are scraped. Upon completion, this function returns the list of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e1c609-6d5f-472b-8ec0-43d8bb5b8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and formatting the pages corresponding to the heteronym.\n",
    "def ImportPDF(heteronym, heteronym_pages):\n",
    "\n",
    "    # Importing the PDF.\n",
    "    reader = PdfReader(\"Pessoa.pdf\")\n",
    "    \n",
    "    heteronym = []\n",
    "    # Formatting the PDF.\n",
    "    for page in heteronym_pages:\n",
    "        page = reader.pages[page]\n",
    "        text = page.extract_text(extraction_mode=\"layout\")\n",
    "        heteronym.append(text)\n",
    "\n",
    "    return heteronym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191591a-46ae-4f36-93f3-dbad371e8a2a",
   "metadata": {},
   "source": [
    "### 2.2. Determining the indeces/page numbers of poems which are split across two or more pages.\n",
    "Based on the scraping parameters from the previous function, pages which contain part of a poem which was started on another page always begin with two line breaks followed by either a whitespace or text. The function \"FindIndeces\" uses regular expressions to find pages which start with this pattern. It then stores the indeces of these pages in a list, which is then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740d8898-9c60-4748-a1e4-c2c37ade764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the indeces of each poem which was split across two or more pages.\n",
    "def FindIndeces(heteronym):\n",
    "    indeces = []\n",
    "    marker1 = re.compile(r\"^[\\n\\n]\")\n",
    "    marker2 = re.compile(r\"^[A-Z]\")\n",
    "    for index, page in enumerate(heteronym):\n",
    "        if marker1.match(page):\n",
    "            if page[2] == \" \" or marker2.match(page[2]):\n",
    "                indeces.append(index)\n",
    "\n",
    "    return indeces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85557b1-c731-4f34-be2d-4ac4e0f8e89b",
   "metadata": {},
   "source": [
    "### 2.3. Removing Footnotes\n",
    "Some pages contain footnotes. This function removes them by filtering for, and substituting the \"*\" character with nothing, using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90118a3-aaf8-422f-9799-82cc86b52539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove footnotes and trailing unwanted text\n",
    "def remove_footnotes(text):\n",
    "    # Match only footnotes that are separate from the main content\n",
    "    footnote_pattern = r'^\\*.*$'  # Matches lines starting with '*' on a new line\n",
    "    # Remove footnotes\n",
    "    text = re.sub(footnote_pattern, '', text, flags=re.MULTILINE).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f190f-d7d5-49d5-8437-3ef7b07a79ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.4. Joining Pages\n",
    "This function uses the previously collected list of indeces of pages which include parts of split poems. It does so by applying a series of if-conditions which determine whether a page contains a self-contained poem, the first page of a poem, the last page of a poem, or an in-between page of a poem.\n",
    "\n",
    "The first if-condition applies specifically to two-page poems. It identifies them by checking whether the page before the one being iterated, and the page immediately after is in the indeces list. If this is the case, it joins the page with one page before.\n",
    "\n",
    "The second if-condition applies to the first and second page of poems which are longer than two pages. These pages are identified if one page before the iterated page is not in the list, but the subsequent page is in the list.\n",
    "\n",
    "The third if-condition applies to all pages of multi-page poems except for the first, second and last. If both the previous page, and the subsequent page are in the indeces list, this page is flagged.\n",
    "\n",
    "Finally, the fouth if-condition applies to the final page of multi-page poems. It applies if the previous page is in the indeces list, but the subsequent page is not in the indeces list.\n",
    "\n",
    "For each of these conditions, the relevant pages are added to the \"pages_to_join\" list, which, upon all pages being gathered (and any footnotes removed), is joined, added to the \"heteronym_joined\" list, and emptied again for the next poem.\n",
    "\n",
    "The second for-loop in this function adds poems to the \"heteronym_joined\" list which only span a single page, so that, in the end, all poems are joined and together in a single list, which is returned upon execution of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2417a918-05f3-4695-84eb-e881e42f7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining poems which were split across multiple pages into one.\n",
    "def JoinPages(heteronym):\n",
    "    heteronym_joined = []\n",
    "    pages_to_join = []\n",
    "    for index in indeces:\n",
    "        # Handling multi-page poems\n",
    "        if index - 1 not in indeces and index + 1 not in indeces:\n",
    "            # Single split\n",
    "            pages_to_join.append(heteronym[index - 1]) # First page\n",
    "            pages_to_join.append(heteronym[index]) # Second page\n",
    "            poem = \"\".join(pages_to_join)\n",
    "            poem = remove_footnotes(poem)  # Apply footnote removal\n",
    "            heteronym_joined.append(poem)\n",
    "            pages_to_join = []\n",
    "        elif index - 1 not in indeces and index + 1 in indeces:\n",
    "            # First page of a multi-page poem\n",
    "            pages_to_join.append(heteronym[index - 1]) # First page\n",
    "            pages_to_join.append(heteronym[index]) # Second page\n",
    "        elif index - 1 in indeces and index + 1 in indeces:\n",
    "            pages_to_join.append(heteronym[index]) # Middle pages\n",
    "        elif index - 1 in indeces and index + 1 not in indeces:\n",
    "            pages_to_join.append(heteronym[index]) # Last page\n",
    "            poem = \"\".join(pages_to_join)\n",
    "            poem = remove_footnotes(poem)  # Apply footnote removal\n",
    "            heteronym_joined.append(poem)\n",
    "            pages_to_join = []\n",
    "\n",
    "    for poem in heteronym:\n",
    "        # Handling single-page poems\n",
    "        if heteronym.index(poem) not in indeces and heteronym.index(poem) + 1 not in indeces:\n",
    "            poem = remove_footnotes(poem)  # Apply footnote removal\n",
    "            heteronym_joined.append(poem)\n",
    "    \n",
    "    return heteronym_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5becf7a-a64e-402f-9583-f5c79b2cadad",
   "metadata": {},
   "source": [
    "### 2.5. Cleaning and tokenizing the poems\n",
    "This function cleans, tokenizes and reformats the joined poems. For each poem, regular expressions are used to remove excess line-breaks, whitespaces and dates. Next, the poem is tokenized. It is then processed in three ways: Firstly, it is tokenized with stopwords removed (and later saved in the \"heteronym_tokenized\" list). Secondly, the tokens are rejoined with punctuation kept in the poem, and only line breaks removed (this is saved in the \"heteronym_formatted\" list). Thirdly, the \"heteronym_cleaned\" list contains the poems with all linebreaks and punctuation removed. The final step is that all tokens are added to an \"all_tokens\" list, if they are not already in there.\n",
    "\n",
    "The function returns a tuple of \"heteronym_cleaned\", \"heteronym_tokenized\", \"all_tokens\" and \"heteronym_formatted\". When calling the function, the variable being returned can be selected with the index of the list in square brackets after the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1444e770-569e-4a7e-9eb6-54e8a91549b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and tokenizing the poems\n",
    "def CleanedTokenized(heteronym_joined):\n",
    "    heteronym_formatted =[]\n",
    "    heteronym_cleaned = []\n",
    "    heteronym_tokenized = []\n",
    "    all_tokens = []  # A list to hold all tokens for total count\n",
    "    \n",
    "    for poem in heteronym_joined:\n",
    "        poem = re.sub(r'\\n', ' ', poem)  # Remove newlines\n",
    "        poem = re.sub(r'\\s+', ' ', poem)  # Collapse multiple spaces\n",
    "        # The following two lines of code will remove the months formatted with a first capitalized letter\n",
    "        poem = re.sub(r'\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\b', '', poem)  # Remove all the months\n",
    "        poem = re.sub(r'\\d+', '', poem)  # Remove all the digits\n",
    "        heteronym_formatted.append(poem)\n",
    "\n",
    "        \n",
    "        # Tokenization and stopwords removal\n",
    "        tokens = re.findall(r'\\w+', poem)  # Tokenize without punctuation\n",
    "        formatted_poem = \" \".join(tokens)  # Saves the poem with new lines and excess whitespace removed.\n",
    "        for index, char in enumerate(formatted_poem):  # Removes extra spaces before or after punctuation.\n",
    "            if char in \".,-?:')!;\":\n",
    "                formatted_poem = re.sub(r\"\\s+([.,-?:\\''’)!;])\", r'\\1', formatted_poem)\n",
    "            if char in r\"(’\":\n",
    "                formatted_poem = re.sub(r\"([(’])\\s+\", r'\\1', formatted_poem)\n",
    "        heteronym_cleaned.append(formatted_poem) # Saves the poem in a list\n",
    "        \n",
    "        filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words]  # Remove stopwords\n",
    "        heteronym_tokenized.append(filtered_tokens) # We want to leave only the tokenized content words in our heteronym_tokenized variable\n",
    "        \n",
    "        all_tokens.extend(filtered_tokens)  # Add filtered tokens to the all_tokens list\n",
    "\n",
    "    return heteronym_cleaned, heteronym_tokenized, all_tokens, heteronym_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d7dba-50bb-4809-ba41-69046872dad2",
   "metadata": {},
   "source": [
    "### 2.6. Creating a dataframe for each list of poems\n",
    "This function first creates a dictionary in which each poem is assigned a number in the key, and the value is the cleaned poem. Subsequently, a dataframe is created containing the dictionary. Next, the \"heteronym_formatted\" and \"heteronym_tokenized\" lists are added, as well as another column containing the name of the heteronym.\n",
    "\n",
    "The function returns a tuple of the dataframe, and heteronym_dict. When calling the function, the variable being returned can be selected with the index of the list in square brackets after the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d22584-7d12-46bc-bf24-f95550bc10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame that will store the poems for each heteronym and Pessoa himself\n",
    "def GetDF(heteronym, heteronym_cleaned, heteronym_formatted, heteronym_tokenized):\n",
    "    heteronym_dict = {}\n",
    "    n = 1\n",
    "    for poem in heteronym_cleaned:\n",
    "        heteronym_dict[\"poem_\"+str(n)] = poem\n",
    "        n += 1\n",
    "    \n",
    "    # Adding Caeiro's poems into a Df.\n",
    "    df = pd.DataFrame(list(heteronym_dict.items()), columns=[\"Index\", \"Cleaned_text\"])\n",
    "    df[\"Formatted_text\"] = heteronym_formatted\n",
    "    df[\"Tokenized_text_Content\"] = heteronym_tokenized\n",
    "    df[\"Heteronym\"] = heteronym\n",
    "    \n",
    "    return df, heteronym_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f197c9-c07b-4d50-9cbf-ee3f80063c40",
   "metadata": {},
   "source": [
    "### 2.7. Exporting the poems to .txt\n",
    "This function creates a folder in the working directory for each heteronym (if this doesn't already exist), and saves each formatted poem as a .txt file in that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841adcb4-3f0b-4420-aeab-ac6f9fe39265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the corpus to .txt files.\n",
    "def ExportToTxt(heteronym, heteronym_dict):  # This relies on the previous function outputting the heteronym's dictionary.\n",
    "    if heteronym not in os.listdir():\n",
    "        os.mkdir(heteronym)  # Creates a folder for the heteronym if it doesn't already exist.\n",
    "    for key in heteronym_dict:\n",
    "        if key + \".txt\" not in os.listdir(heteronym + \"/\"):  # Creates the file if it doesn't already exist.\n",
    "            file = open(heteronym + \"/\" + key + \".txt\", \"x\")\n",
    "            file.close()\n",
    "        with open(heteronym + \"/\" + key + \".txt\", \"w\", encoding=\"utf-8\") as file:  # Writes into the file.\n",
    "            file.write(heteronym_dict[key])\n",
    "    \n",
    "    return \"Complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5671c9-819f-4729-98ad-7c0d30715f3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Applying the functions to Pessoa and His Heteronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637beea-32c9-486c-87f3-29d53017e582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1. Alberto Caeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cbfa847-447f-476a-9e28-637b87888012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the PDF:\n",
    "caeiro = ImportPDF(\"caeiro\", range(56,126))\n",
    "\n",
    "# Stripping the top of the pages and other unnecessary details.\n",
    "for page in caeiro:\n",
    "    if \"a little larger than the entire universe\" in page:\n",
    "        caeiro[caeiro.index(page)] = page[2:].lstrip(\"a little larger than the entire universe\")\n",
    "    if \"alberto caeiro\" in page:\n",
    "        caeiro[caeiro.index(page)] = page.strip(\"alberto caeiro\")[2:]\n",
    "    if \"alber t o caeiro\" in page:\n",
    "        caeiro[caeiro.index(page)] = page.strip(\"alber t o caeiro\")[2:]\n",
    "    if len(page) == 0:\n",
    "        caeiro.remove(page)\n",
    "    if \"            from\\nTHE SHEPHERD IN LOVE\" in page or \"           from\\nUNCOLLECTED POEMS\" in page:\n",
    "        caeiro.remove(page)\n",
    "\n",
    "# Finding the indices of each poem split across two or more pages.\n",
    "indeces = FindIndeces(caeiro)\n",
    "\n",
    "# Joining poems which are split across multiple pages.\n",
    "caeiro_joined = JoinPages(caeiro)\n",
    "\n",
    "# Removing empty list entries.\n",
    "caeiro_joined = [poem for poem in caeiro_joined if len(poem.strip()) > 0]\n",
    "\n",
    "# Cleaning and tokenizing the poems.\n",
    "caeiro_cleaned = CleanedTokenized(caeiro_joined)[0]\n",
    "caeiro_tokenized = CleanedTokenized(caeiro_joined)[1]\n",
    "caeiro_formatted = CleanedTokenized(caeiro_joined)[3]\n",
    "\n",
    "# Count the total number of content words.\n",
    "caeiro_all_tokens = CleanedTokenized(caeiro_joined)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716b4c5-42cf-43eb-86b7-b29b92339a75",
   "metadata": {},
   "source": [
    "First, we will keep track of each heteronyms' corpus size, since it will be relevant for parts of our analysis. As mentioned before, we will be observing mostly the content words, since they are more relevant for most parts of our analysis. For the sentiment analysis, the function uses a different variable, which stores the entire texts of the poems, with the punctuation and function words included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7d6a79-d529-471d-9409-8eeea7d04520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caeiro's corpus comprises 3522 content words.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Caeiro's corpus comprises\", len(caeiro_all_tokens), \"content words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67b6456-2d17-4c4b-acb8-d9d6c72ce02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>Formatted_text</th>\n",
       "      <th>Tokenized_text_Content</th>\n",
       "      <th>Heteronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poem_1</td>\n",
       "      <td>II My gaze is clear like a sunﬂower It is my c...</td>\n",
       "      <td>II My gaze is clear like a sunﬂower. It is my ...</td>\n",
       "      <td>[ii, gaze, clear, like, sunﬂower, custom, walk...</td>\n",
       "      <td>Caeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poem_2</td>\n",
       "      <td>IV This afternoon a thunderstorm Rolled down f...</td>\n",
       "      <td>IV This afternoon a thunderstorm Rolled down f...</td>\n",
       "      <td>[iv, afternoon, thunderstorm, rolled, slopes, ...</td>\n",
       "      <td>Caeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poem_3</td>\n",
       "      <td>VIII One midday in late spring I had a dream t...</td>\n",
       "      <td>VIII One midday in late spring I had a dream t...</td>\n",
       "      <td>[viii, one, midday, late, spring, dream, like,...</td>\n",
       "      <td>Caeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poem_4</td>\n",
       "      <td>XXVIII Today I read nearly two pages In the bo...</td>\n",
       "      <td>XXVIII Today I read nearly two pages In the bo...</td>\n",
       "      <td>[xxviii, today, read, nearly, two, pages, book...</td>\n",
       "      <td>Caeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem_5</td>\n",
       "      <td>XLVI In this way or that way As it may happen ...</td>\n",
       "      <td>XLVI In this way or that way, As it may happen...</td>\n",
       "      <td>[xlvi, way, way, may, happen, happen, sometime...</td>\n",
       "      <td>Caeiro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                       Cleaned_text  \\\n",
       "0  poem_1  II My gaze is clear like a sunﬂower It is my c...   \n",
       "1  poem_2  IV This afternoon a thunderstorm Rolled down f...   \n",
       "2  poem_3  VIII One midday in late spring I had a dream t...   \n",
       "3  poem_4  XXVIII Today I read nearly two pages In the bo...   \n",
       "4  poem_5  XLVI In this way or that way As it may happen ...   \n",
       "\n",
       "                                      Formatted_text  \\\n",
       "0  II My gaze is clear like a sunﬂower. It is my ...   \n",
       "1  IV This afternoon a thunderstorm Rolled down f...   \n",
       "2  VIII One midday in late spring I had a dream t...   \n",
       "3  XXVIII Today I read nearly two pages In the bo...   \n",
       "4  XLVI In this way or that way, As it may happen...   \n",
       "\n",
       "                              Tokenized_text_Content Heteronym  \n",
       "0  [ii, gaze, clear, like, sunﬂower, custom, walk...    Caeiro  \n",
       "1  [iv, afternoon, thunderstorm, rolled, slopes, ...    Caeiro  \n",
       "2  [viii, one, midday, late, spring, dream, like,...    Caeiro  \n",
       "3  [xxviii, today, read, nearly, two, pages, book...    Caeiro  \n",
       "4  [xlvi, way, way, may, happen, happen, sometime...    Caeiro  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Present the corpus as a DataFrame.\n",
    "caeiro_df = GetDF(\"Caeiro\", caeiro_cleaned, caeiro_formatted, caeiro_tokenized)[0]\n",
    "caeiro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "664ba974-85a9-48e5-a042-65dc8e7a7f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports the corpus to .txt files.\n",
    "caeiro_dict = GetDF(\"Caeiro\", caeiro_formatted, caeiro_cleaned, caeiro_tokenized)[1]\n",
    "ExportToTxt(\"Caeiro\", caeiro_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d23f9e-c9a7-4e8a-8703-b6cc22756065",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2. Ricardo Reis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a59a54b6-a75c-48e7-b00e-e82cf2944618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reis' corpus comprises 2234 content words.\n"
     ]
    }
   ],
   "source": [
    "#Importing the PDF\n",
    "reis = ImportPDF(\"reis\", range(128,189))\n",
    "\n",
    "# Stripping the top of the pages and other unnecessary details.\n",
    "for page in reis:\n",
    "    if \"a little larger than the entire universe\" in page:\n",
    "        reis[reis.index(page)] = page[2:].lstrip(\" 0123456789 a little larger than the entire universe\")\n",
    "    if \"ricardo reis\" in page[:12]:\n",
    "        reis[reis.index(page)] = page.lstrip(\"Ricardo reis\")[2:]\n",
    "    if len(page) == 0:\n",
    "        reis.remove(page)\n",
    "\n",
    "# Finding the indices of each poem split across two or more pages.\n",
    "indeces = FindIndeces(reis)\n",
    "\n",
    "# Joining poems which are split across multiple pages.\n",
    "reis_joined = JoinPages(reis)\n",
    "\n",
    "# Removing empty list entries\n",
    "reis_joined = [poem for poem in reis_joined if len(poem.strip()) > 0]\n",
    "\n",
    "# Cleaning and tokenizing the poems\n",
    "reis_cleaned = CleanedTokenized(reis_joined)[0]\n",
    "reis_tokenized = CleanedTokenized(reis_joined)[1]\n",
    "reis_formatted = CleanedTokenized(reis_joined)[3]\n",
    "\n",
    "# Count the total number of content words\n",
    "reis_all_tokens = CleanedTokenized(reis_joined)[2]\n",
    "print(f\"Reis' corpus comprises\", len(reis_all_tokens), \"content words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18ef3ad-6c93-402b-a834-39a87abbb0a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>Formatted_text</th>\n",
       "      <th>Tokenized_text_Content</th>\n",
       "      <th>Heteronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poem_1</td>\n",
       "      <td>To Alberto Caeiro Peaceful Master Are all the ...</td>\n",
       "      <td>To Alberto Caeiro Peaceful, Master, Are all th...</td>\n",
       "      <td>[alberto, caeiro, peaceful, master, hours, los...</td>\n",
       "      <td>Reis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poem_2</td>\n",
       "      <td>Each thing in its time has its time The trees ...</td>\n",
       "      <td>Each thing, in its time, has its time. The tre...</td>\n",
       "      <td>[thing, time, time, trees, blossom, winter, wh...</td>\n",
       "      <td>Reis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poem_3</td>\n",
       "      <td>THE CHESS PLAYERS I ve heard that once during ...</td>\n",
       "      <td>THE CHESS PLAYERS I’ve heard that once, during...</td>\n",
       "      <td>[chess, players, heard, know, war, persia, inv...</td>\n",
       "      <td>Reis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poem_4</td>\n",
       "      <td>I love the roses of Adonis s gardens Yes Lydia...</td>\n",
       "      <td>I love the roses of Adonis’s gardens. Yes, Lyd...</td>\n",
       "      <td>[love, roses, adonis, gardens, yes, lydia, lov...</td>\n",
       "      <td>Reis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem_5</td>\n",
       "      <td>The god Pan isn t dead In each ﬁeld that shows...</td>\n",
       "      <td>The god Pan isn’t dead. In each ﬁeld that show...</td>\n",
       "      <td>[god, pan, dead, ﬁeld, shows, ceres, naked, br...</td>\n",
       "      <td>Reis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                       Cleaned_text  \\\n",
       "0  poem_1  To Alberto Caeiro Peaceful Master Are all the ...   \n",
       "1  poem_2  Each thing in its time has its time The trees ...   \n",
       "2  poem_3  THE CHESS PLAYERS I ve heard that once during ...   \n",
       "3  poem_4  I love the roses of Adonis s gardens Yes Lydia...   \n",
       "4  poem_5  The god Pan isn t dead In each ﬁeld that shows...   \n",
       "\n",
       "                                      Formatted_text  \\\n",
       "0  To Alberto Caeiro Peaceful, Master, Are all th...   \n",
       "1  Each thing, in its time, has its time. The tre...   \n",
       "2  THE CHESS PLAYERS I’ve heard that once, during...   \n",
       "3  I love the roses of Adonis’s gardens. Yes, Lyd...   \n",
       "4  The god Pan isn’t dead. In each ﬁeld that show...   \n",
       "\n",
       "                              Tokenized_text_Content Heteronym  \n",
       "0  [alberto, caeiro, peaceful, master, hours, los...      Reis  \n",
       "1  [thing, time, time, trees, blossom, winter, wh...      Reis  \n",
       "2  [chess, players, heard, know, war, persia, inv...      Reis  \n",
       "3  [love, roses, adonis, gardens, yes, lydia, lov...      Reis  \n",
       "4  [god, pan, dead, ﬁeld, shows, ceres, naked, br...      Reis  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Present the corpus as a DataFrame.\n",
    "reis_df = GetDF(\"Reis\", reis_cleaned, reis_formatted, reis_tokenized)[0]\n",
    "reis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4142b8da-8651-4f2e-b39a-e2376c7a5fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports the corpus to .txt files.\n",
    "reis_dict = GetDF(\"Reis\", reis_formatted, reis_cleaned, reis_tokenized)[1]\n",
    "ExportToTxt(\"Reis\", reis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4f657-05c8-4e9d-aa69-30d8e2f84cf2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.3. Álvaro de Campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e2072b5-71d3-4af0-afd4-4cb040aaafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos' corpus comprises 12223 content words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the PDF.\n",
    "campos = ImportPDF(\"campos\", range(192,318))\n",
    "\n",
    "# stripping the top of the pages, and dates at the end.\n",
    "# Due to how the PDF was imported, I had to apply several different parameters here.\n",
    "for page in campos:\n",
    "    if \"a little larger than the entire universe\" in page:\n",
    "        campos[campos.index(page)] = page.lstrip(\" 0123456789 a little larger than the entire universe\")\n",
    "    if \"álvaro de campos\" in page[:16]:\n",
    "        campos[campos.index(page)] = page.lstrip(\"álvaro de campos\")[3:]\n",
    "    if \"álva r o de campos\" in page[:18]:\n",
    "        campos[campos.index(page)] = page.lstrip(\"álvaro de campos\")[3:]\n",
    "    if len(page) == 0:\n",
    "        campos.remove(page)\n",
    "\n",
    "# Finding the indices of each poem split across two or more pages.\n",
    "indeces = FindIndeces(campos)\n",
    "\n",
    "# Joining poems which are split across multiple pages.\n",
    "campos_joined = JoinPages(campos)\n",
    "\n",
    "# Joining the poems results in a few more empty list entries, which are removed here.\n",
    "campos_joined = [poem for poem in campos_joined if len(poem.strip()) > 0]\n",
    "\n",
    "\n",
    "# Cleaning and tokenizing the poems\n",
    "campos_cleaned = []\n",
    "campos_tokenized = []\n",
    "\n",
    "# Cleaning and tokenizing the poems\n",
    "campos_cleaned = CleanedTokenized(campos_joined)[0]\n",
    "campos_tokenized = CleanedTokenized(campos_joined)[1]\n",
    "campos_formatted = CleanedTokenized(campos_joined)[3]\n",
    "\n",
    "# Count the total number of content words.\n",
    "campos_all_tokens = CleanedTokenized(campos_joined)[2]\n",
    "print(f\"Campos' corpus comprises\", len(campos_all_tokens), \"content words.\")\n",
    "\n",
    "len(campos_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe981cb-e819-4fde-be4c-9c7c8f0efb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>Formatted_text</th>\n",
       "      <th>Tokenized_text_Content</th>\n",
       "      <th>Heteronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poem_1</td>\n",
       "      <td>OPIARY It s before I take opium that my soul i...</td>\n",
       "      <td>OPIARY It’s before I take opium that my soul i...</td>\n",
       "      <td>[opiary, take, opium, soul, sick, feel, life, ...</td>\n",
       "      <td>Campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poem_2</td>\n",
       "      <td>TRIUMPHAL ODE By the painful light of the fact...</td>\n",
       "      <td>TRIUMPHAL ODE By the painful light of the fact...</td>\n",
       "      <td>[triumphal, ode, painful, light, factory, huge...</td>\n",
       "      <td>Campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poem_3</td>\n",
       "      <td>EXCERPTS FROM TWO ODES I Come ancient and unch...</td>\n",
       "      <td>EXCERPTS FROM TWO ODES I Come, ancient and unc...</td>\n",
       "      <td>[excerpts, two, odes, come, ancient, unchangin...</td>\n",
       "      <td>Campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poem_4</td>\n",
       "      <td>MARITIME ODE Alone this summer morning on the ...</td>\n",
       "      <td>MARITIME ODE Alone this summer morning on the ...</td>\n",
       "      <td>[maritime, ode, alone, summer, morning, desert...</td>\n",
       "      <td>Campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem_5</td>\n",
       "      <td>SALUTATION TO WALT WHITMAN Portugal Inﬁnity el...</td>\n",
       "      <td>SALUTATION TO WALT WHITMAN Portugal, Inﬁnity— ...</td>\n",
       "      <td>[salutation, walt, whitman, portugal, inﬁnity,...</td>\n",
       "      <td>Campos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                       Cleaned_text  \\\n",
       "0  poem_1  OPIARY It s before I take opium that my soul i...   \n",
       "1  poem_2  TRIUMPHAL ODE By the painful light of the fact...   \n",
       "2  poem_3  EXCERPTS FROM TWO ODES I Come ancient and unch...   \n",
       "3  poem_4  MARITIME ODE Alone this summer morning on the ...   \n",
       "4  poem_5  SALUTATION TO WALT WHITMAN Portugal Inﬁnity el...   \n",
       "\n",
       "                                      Formatted_text  \\\n",
       "0  OPIARY It’s before I take opium that my soul i...   \n",
       "1  TRIUMPHAL ODE By the painful light of the fact...   \n",
       "2  EXCERPTS FROM TWO ODES I Come, ancient and unc...   \n",
       "3  MARITIME ODE Alone this summer morning on the ...   \n",
       "4  SALUTATION TO WALT WHITMAN Portugal, Inﬁnity— ...   \n",
       "\n",
       "                              Tokenized_text_Content Heteronym  \n",
       "0  [opiary, take, opium, soul, sick, feel, life, ...    Campos  \n",
       "1  [triumphal, ode, painful, light, factory, huge...    Campos  \n",
       "2  [excerpts, two, odes, come, ancient, unchangin...    Campos  \n",
       "3  [maritime, ode, alone, summer, morning, desert...    Campos  \n",
       "4  [salutation, walt, whitman, portugal, inﬁnity,...    Campos  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Present the corpus as a DataFrame.\n",
    "campos_df = GetDF(\"Campos\", campos_cleaned, campos_formatted, campos_tokenized)[0]\n",
    "campos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44970c33-a17f-4a96-9175-095a6a6778d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports the corpus to .txt files.\n",
    "campos_dict = GetDF(\"Campos\", campos_formatted, campos_cleaned, campos_tokenized)[1]\n",
    "ExportToTxt(\"Campos\", campos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a448832-5921-477d-adbb-dbcdcb389688",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.4. Fernando Pessoa - Himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2693cbc-bfdd-4361-90b7-11df70ed58c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pessoa's corpus comprises 4848 content words.\n"
     ]
    }
   ],
   "source": [
    "# Importing the PDF.\n",
    "pessoa = ImportPDF(\"pessoa\", range(322,428))\n",
    "\n",
    "# stripping the top of the pages, and dates at the end.\n",
    "# Due to how the PDF was imported, I had to apply several different parameters here.\n",
    "for page in pessoa:\n",
    "    if \"a little larger than the entire universe\" in page:\n",
    "        pessoa[pessoa.index(page)] = page.lstrip(\" 0123456789 a little larger than the entire universe\")\n",
    "    if \"fernando pessoa–himself\" in page[:23]:\n",
    "        pessoa[pessoa.index(page)] = page.lstrip(\"fernando pessoa–himself\")[3:]\n",
    "    if len(page) == 0:\n",
    "        pessoa.remove(page)\n",
    "\n",
    "# Finding the indices of each poem split across two or more pages.\n",
    "indeces = FindIndeces(pessoa)\n",
    "\n",
    "# Joining poems which are split across multiple pages.\n",
    "pessoa_joined = JoinPages(pessoa)\n",
    "\n",
    "# Joining the poems results in a few more empty list entries, which are removed here.\n",
    "pessoa_joined = [poem for poem in pessoa_joined if len(poem.strip()) > 0]\n",
    "\n",
    "# Cleaning and tokenizing the poems\n",
    "pessoa_cleaned = CleanedTokenized(pessoa_joined)[0]\n",
    "pessoa_tokenized = CleanedTokenized(pessoa_joined)[1]\n",
    "pessoa_formatted = CleanedTokenized(pessoa_joined)[3]\n",
    "\n",
    "# Count the total number of tokens\n",
    "pessoa_all_tokens = CleanedTokenized(pessoa_joined)[2]\n",
    "print(f\"Pessoa's corpus comprises\", len(pessoa_all_tokens), \"content words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd333e49-a63b-40c5-8fa0-9baf482ee087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>Formatted_text</th>\n",
       "      <th>Tokenized_text_Content</th>\n",
       "      <th>Heteronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poem_1</td>\n",
       "      <td>Swamps of yearnings brushing against my gilded...</td>\n",
       "      <td>Swamps of yearnings brushing against my gilded...</td>\n",
       "      <td>[swamps, yearnings, brushing, gilded, soul, di...</td>\n",
       "      <td>Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poem_2</td>\n",
       "      <td>from SLANTING RAIN I My dream of an inﬁnite po...</td>\n",
       "      <td>from SLANTING RAIN I My dream of an inﬁnite po...</td>\n",
       "      <td>[slanting, rain, dream, inﬁnite, port, crosses...</td>\n",
       "      <td>Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poem_3</td>\n",
       "      <td>She sings poor reaper perhaps Believing hersel...</td>\n",
       "      <td>She sings, poor reaper, perhaps Believing hers...</td>\n",
       "      <td>[sings, poor, reaper, perhaps, believing, happ...</td>\n",
       "      <td>Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poem_4</td>\n",
       "      <td>DIARY IN THE SHADE Do you still remember me Yo...</td>\n",
       "      <td>DIARY IN THE SHADE Do you still remember me? Y...</td>\n",
       "      <td>[diary, shade, still, remember, knew, long, ti...</td>\n",
       "      <td>Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem_5</td>\n",
       "      <td>Where s my life going and who s taking it ther...</td>\n",
       "      <td>Where’s my life going, and who’s taking it the...</td>\n",
       "      <td>[life, going, taking, always, want, destiny, k...</td>\n",
       "      <td>Pessoa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                       Cleaned_text  \\\n",
       "0  poem_1  Swamps of yearnings brushing against my gilded...   \n",
       "1  poem_2  from SLANTING RAIN I My dream of an inﬁnite po...   \n",
       "2  poem_3  She sings poor reaper perhaps Believing hersel...   \n",
       "3  poem_4  DIARY IN THE SHADE Do you still remember me Yo...   \n",
       "4  poem_5  Where s my life going and who s taking it ther...   \n",
       "\n",
       "                                      Formatted_text  \\\n",
       "0  Swamps of yearnings brushing against my gilded...   \n",
       "1  from SLANTING RAIN I My dream of an inﬁnite po...   \n",
       "2  She sings, poor reaper, perhaps Believing hers...   \n",
       "3  DIARY IN THE SHADE Do you still remember me? Y...   \n",
       "4  Where’s my life going, and who’s taking it the...   \n",
       "\n",
       "                              Tokenized_text_Content Heteronym  \n",
       "0  [swamps, yearnings, brushing, gilded, soul, di...    Pessoa  \n",
       "1  [slanting, rain, dream, inﬁnite, port, crosses...    Pessoa  \n",
       "2  [sings, poor, reaper, perhaps, believing, happ...    Pessoa  \n",
       "3  [diary, shade, still, remember, knew, long, ti...    Pessoa  \n",
       "4  [life, going, taking, always, want, destiny, k...    Pessoa  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Present the corpus as a DataFrame.\n",
    "pessoa_df = GetDF(\"Pessoa\", pessoa_cleaned, pessoa_formatted, pessoa_tokenized)[0]\n",
    "pessoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc5f496-5602-49fd-b8dc-6a6727ea9fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports the corpus to .txt files.\n",
    "pessoa_dict = GetDF(\"Pessoa\", pessoa_formatted, pessoa_cleaned, pessoa_tokenized)[1]\n",
    "ExportToTxt(\"Pessoa\", pessoa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25550d-b548-4386-ac5f-9cc17c0b2a12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Exporting the joined DF to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23109572-52fb-4d1c-bb57-9dce6d45c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DF containing all four heteronyms' corpora.\n",
    "all_df = pd.concat([caeiro_df, reis_df, campos_df, pessoa_df], axis=0)\n",
    "all_df.to_csv(\"pessoa_heteronyms_full_corpus.csv\")  # Exporting the DF to a .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e57474-0c28-42e9-91d7-184a6ca5de10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840c1fc-3440-4a17-b85d-d9628b2ff04e",
   "metadata": {},
   "source": [
    "Pessoa, F., & Zenith, R. (2014). A little larger than the entire universe: Selected poems. Penguin Books.\n",
    "\n",
    "Encyclopædia Britannica, inc. (2025, January 3). Horace. Encyclopædia Britannica. https://www.britannica.com/biography/Horace-Roman-poet\n",
    "\n",
    "Poetry Foundation. (2025). Ode. Poetry Foundation. https://www.poetryfoundation.org/education/glossary/ode\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
